# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix

df=pd.read_csv('titanic.csv')

df.head()

df.info()

df.describe()

df.shape

df.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)

df.isnull().sum()

df['Age'].fillna(df['Age'].mean(),inplace=True)

df['Embarked'].fillna(df['Embarked'].mode()[0],inplace=True)

df.isnull().sum()

df.drop_duplicates(inplace=True)

df.head()

numeric_columns=['Survived','Pclass','SibSp','Parch','Fare']

for col in numeric_columns:
    plt.figure(figsize=(10,5))
    sns.histplot(df[col])
    plt.show()

for col in numeric_columns:
    plt.figure(figsize=(10,5))
    sns.boxplot(df[col])
    plt.show()

sns.countplot(x=df['Survived'])

sns.countplot(x=df['Sex'])

sns.countplot(x=df['Pclass'])

sns.countplot(x=df['Embarked'])

sns.countplot(x=df['SibSp'])

sns.heatmap(df.corr(numeric_only=True),annot=True)

le=LabelEncoder()
df['Sex']=le.fit_transform(df['Sex'])

df=pd.get_dummies(df,columns=['Embarked','Pclass'])

df=df.astype('int64')

df.head()

scale=StandardScaler()
df['Age']=scale.fit_transform(df[['Age']])
df['Fare']=scale.fit_transform(df[['Fare']])

df.head()

x=df.drop('Survived',axis=1)
y=df['Survived']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.model_selection import RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier

# Parameter grid (search space)
param_dist = {
    'max_depth': [None, 3, 5, 7, 10, 15, 20],          # tree ki depth
    'min_samples_split': [2, 5, 10, 15, 20],           # split hone ke liye minimum samples
    'min_samples_leaf': [1, 2, 4, 6, 8, 10],           # leaf node pe min samples
    'max_features': [None, 'sqrt', 'log2']             # feature selection
}

# Base model
dt = DecisionTreeClassifier(random_state=42)

# Randomized search
random_search = RandomizedSearchCV(
    estimator=dt,
    param_distributions=param_dist,
    n_iter=20,                # 20 random combinations try karega
    cv=5,                     # 5-fold cross validation
    scoring='accuracy',       # accuracy ke basis pe best model choose hoga
    random_state=42,
    n_jobs=-1                 # parallel processing
)

# Fit on training data
random_search.fit(x_train, y_train)

# Best parameters aur score
print("Best Parameters:", random_search.best_params_)
print("Best CV Accuracy:", random_search.best_score_)

# Best model se prediction
best_model = random_search.best_estimator_
y_pred = best_model.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

model = DecisionTreeClassifier(
    max_depth=20,
    min_samples_split=20,
    min_samples_leaf=2,
    max_features=None,
    random_state=42)
model.fit(x_train,y_train)

y_pred = model.predict(x_test)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))